---
title: "Exam_preperation"
author: "Amieroh Abrahams"
date: "09 August 2018"
output: html_document
---

The packages needed for this is

```{r}
library(tidyverse)
library(vegan)
library(ade4)
library(vegan)
library(gclus)
library(ape)
```

```{r}
spe <- DoubsSpe
spa <- DoubsSpa
env <- DoubsEnv
```


####################CHAPTER2#####################

Things to do when analysing the data

```{r}


spe			# Display the whole data frame in the console
			# Not recommended for large datasets!
spe[1:5,1:10]		# Display only 5 lines and 10 columns
head(spe)			# Display only the first 6 lines
nrow(spe)			# Number of rows (sites)
ncol(spe)			# Number of columns (species)
dim(spe)			# Dimensions of the data frame (rows, columns)
colnames(spe)		# Column labels (descriptors = species)
rownames(spe)		# Row labels (objects = sites)
summary(spe)		# Descriptive- statistics for columns
```

Creating maps and graphs to view the data
This code is found in Exercise 1 and the respective chapters in the numerical ecology book (Base R way)
Notes on diversity also found in the chapter2 as well as determining species distribution and abundance

Now we look at thee decostand function. This function allows us to standardise the data. Species data specifically.

```{r}
?decostand

## Simple transformations
# Partial view of the raw data (abundance codes)
spe[1:5, 2:4]
# Transform abundances to presence-absence (1-0)
spe.pa <- decostand(spe, method="pa")
spe.pa[1:5, 2:4]


## Species profiles: standardization by columns
# Scale abundances by dividing them by the maximum value for each species
# Note: MARGIN=2 (column, default value) for argument "max"
spe.scal <- decostand(spe, "max")
spe.scal[1:5,2:4]
# Display the maximum by column
apply(spe.scal, 2, max)

# Scale abundances by dividing them by the species totals
# (relative abundance by species)
# Note: here, override the default MARGIN=1 argument of "total"
spe.relsp <- decostand(spe, "total", MARGIN=2)
spe.relsp[1:5,2:4]
# Display the sum by column
# Classical: apply(spe.relsp, 2, sum)
colSums(spe.relsp)

## Site profiles: standardization by rows
# Scale abundances by dividing them by the site totals
# (relative abundance by site)
spe.rel <- decostand(spe, "total") # default MARGIN=1
spe.rel[1:5,2:4]
# Display the sum of row vectors to determine if the scaling worked properly
# Classical: apply(spe.rel, 1, sum)
rowSums(spe.rel)

# Give a length of 1 to each row vector (Euclidean norm)
# This is called the chord transformation
spe.norm <- decostand(spe, "normalize") # default MARGIN=1
spe.norm[1:5,2:4]
# Verify the norm of row vectors
norm <- function(x) sqrt(x%*%x)
apply(spe.norm, 1, norm)

# Compute square root of relative abundances by site
# This is called the Hellinger transformation
spe.hel <- decostand(spe, "hellinger")
spe.hel[1:5,2:4]
# Check the norm of row vectors
apply(spe.hel, 1, norm)


## Double profiles: standardization by columns and rows
# Chi-square transformation
spe.chi <- decostand(spe, "chi.square")
spe.chi[1:5,2:4]
# Check what happened to site 8 where no species was found
spe.chi[7:9,]

# Wisconsin standardization
# Abundances are first ranged by species maxima and then by site totals
spe.wis <- wisconsin(spe)
spe.wis[1:5,2:4]

```

The simple transformations for the environmental datasets

```{r}
# Simple transformation of an environmental variable
# Standardization of all environmental variables
# Center and scale = standardize variables (z-scores)
env.z <- decostand(env, "standardize")
apply(env.z, 2, mean)	# means = 0
apply(env.z, 2, sd)		# standard deviations = 1

# Same standardization using the scale() function (which returns a matrix)
env.z <- as.data.frame(scale(env))
```

####################CHAPTER 3########################################

Focusing on the Qmode data
Here we are doing the dissimilarity for the different types of datasets - this includes analysis for the binary data- presence or absence data.

```{r}
# Q-mode dissimilarity and distance measures for (semi-)quantitative data
# Percentage difference (Bray-Curtis) dissimilarity matrix
# on raw species data
spe.db <- vegdist(spe)	# method="bray" (default)
head(spe.db)

# Percentage difference (Bray-Curtis) dissimilarity matrix
# on log-transformed abundances
spe.dbln <- vegdist(log1p(spe))
head(spe.dbln)
# Chord distance matrix
spe.norm <- decostand(spe, "nor")
spe.dc <- dist(spe.norm)
head(spe.dc)
# Hellinger distance matrix
spe.hel <- decostand(spe, "hel")
spe.dh <- dist(spe.hel)
head(spe.dh)

# Q-mode dissimilarity measures for binary data
# Jaccard dissimilarity matrix using function vegdist()
spe.dj <- vegdist(spe, "jac", binary=TRUE)
head(spe.dj)
head(sqrt(spe.dj))
# Jaccard dissimilarity matrix using function dist()
spe.dj2 <- dist(spe, "binary")
head(spe.dj2)
# Jaccard dissimilarity matrix using function dist.binary()
spe.dj3 <- dist.binary(spe, method=1)
head(spe.dj3)
# Sorensen dissimilarity matrix using function dist.binary()
spe.ds <- dist.binary(spe, method=5)
head(spe.ds)
# Sorensen dissimilarity matrix using function vegdist()
spe.ds2 <- vegdist(spe, binary=TRUE)
head(spe.ds2)
head(sqrt(spe.ds2))
# Ochiai dissimilarity matrix
spe.och <- dist.binary(spe, method=7)
head(spe.och)
```

Here we are working with spatial, environmental and species data. Euclidean distance for each of these datasets. Take note on when to use euclidean distances and when to use hellinger distances.

```{r}
# Compare distance matrices from environmental, species and spatial data

# Remove the 'dfs' variable from the env dataset
env2 <- env[,-1] # here we removing the sites from the environmental data

# Euclidean distance matrix of the standardized env2 data frame
env.de <- dist(scale(env2))
dev.new(title="Environment", width=10, height=5)
coldiss(env.de, nc=16, diag=TRUE)

# Hellinger distance matrix of the species data (equal-sized classes)
dev.new(title="Species", width=10, height=5)
coldiss(spe.dh, nc=16, diag=TRUE)

# Euclidean distance matrix on spatial coordinates (2D)
spa.de <- dist(spa)
dev.new(title="x-y", width=10, height=5)
coldiss(spa.de, nc=16, diag=TRUE)

# Euclidean distance matrix on distance from the source (1D)
dfs.df <- as.data.frame(env$dfs, row.names=rownames(env))
riv.de <- dist(dfs.df)
dev.new(title="Distance from the source", width=10, height=5) 
coldiss(riv.de, nc=16, diag=TRUE)
```

Euclidian distance formulas
```{r}
# Calculating euclidean distances for geographic coordinates
ex.xy.euc <- vegdist(ex.xy, method = "euclidian")

# Calculating euclidean distance on environmental datasets
ex.env.std <- decostand(xy.env, method = "standardize")
ex.env.std

# Now for euclidian distances
ex.env.euc <- vegdist(ex.env.std, method = "euclidian")
ex.env.euc
```

What distance matrix would we use on the doubs species data....either use Bray-Curtis for abundance data or Jaccard for presence and absence data

```{r}
# look at Doubs species data 

# Species (community) data frame (fish abundances)
spe <- read.csv("DoubsSpe.csv", row.names=1)

# bray-curtis for abundance data 
# Jaccard fro presence/ absence data (binary = true)

# Bray or Jaccard? = Bray ONLY FOR SPP

spe_bray <- round(vegdist(spe, method = "bray"), 2)
as.matrix(spe_bray)[, 1:4]

#general trends 
# sites close together (sequential sites), initially have some similarity (< 1), further u move away are very dissimilar (= 1)

# spe_jacc <- round(vegdist(spe, method = "jaccard"), 2)
# spe_jacc

# plot graph 
# ggplot(data.frame(spe_bray), aes(x = "", y = ""))

# create a distance matrix with altitude data,
# euclidian == env data 

alt_num <- data.frame(as.numeric(env$alt))

alt_euc <- vegdist(alt_num, method = "euclidian")
as.matrix(alt_euc)[, 1:4]

plot.dat <- tibble(x = seq (1:30), 
                   h = as.matrix(alt_euc)[, 1])


ggplot(plot.dat, aes(x = x, y = h)) +
  geom_point()
```

Making an artificial dataframe can be found in Chapter 3:
working with five binary data variables in this dataset
This is where they make use of the grower index....analysis

Now we look at the Rmode data
Species dataset: transformations and then doing Euclidean calculations
Plotting of these variables may be found in chapter3 of the numerical ecology book


```{r}
# USE FOR PRESENCE ABSENCE DATA
# Transpose matrix of species abundances
spe.t <- t(spe)
spec.t <- vegdist(spec.t, "jaccard", binary = TRUE)

#####################################################USE THIS FOR THE CA analysis
# Chi-square pre-transformation followed by Euclidean distance
spe.t.chi <- decostand(spe.t, "chi.square")
spe.t.D16 <- dist(spe.t.chi)
dev.new(title="D16 on fish species (R-mode)", width=10, height=5)
coldiss(spe.t.D16, diag=TRUE)

# Jaccard index on fish presence-absence
spe.t.S7 <- vegdist(spe.t, "jaccard", binary=TRUE)
dev.new(title="S7 on fish species (R-mode)", width=10, height=5) 
coldiss(spe.t.S7, diag=TRUE)
```

#########################CHAPTER 5#################################

Loading the various libraries needed for the code to follow

```{r}
library(ade4)
library(vegan)
library(gclus)
library(ape)
library(FactoMineR)
```

Loading the additional files that may be needed when doing Ordinational analysis

```{r}
source("evplot.R")
source("cleanplot.pca.R")
source("PCA.newr.R")
source("CA.newr.R")
```

The next step is to load the data and then explore the data using the basic data steps

The next step is to then make use of the decostand function to standardise the env dataset: this is due to the fact that all the  environmental variables are done using different units

```{r}
# decostand func
env_std <- decostand(env, method = "standardize")

cor(env)
cor(env_std)
# calculating the mean of each of the columns:
round(apply(env_std, 2, FUN = mean, 2)) 
# The first 2 in this formula is to calculate the mean for the column. if the value was 1 then it calculates the rows 
round(apply(env_std, 2, FUN = sd, 2))

env_pca <-  rda(env, scale = TRUE)
sum(env_pca$CA$eig) # Calculating the sum
# What does the correlation matrix mean?
# when you compare a variable with itself it equals 1
# what are eignen values - 
summary(env_pca)
# Species scores - eigan vectors - correltion between unscaled value and the new value
```

Here we run the PCA on the entire environmetal dataset

```{r}
# A reminder of the content of the env dataset
summary(env)
# PCA based on a correlation matrix
# Argument scale=TRUE calls for a standardization of the variables
# Rda different from pca 
env.pca <- rda(env, scale=TRUE) ## Scale : Mean 0 and SD of 1- dont need decostand analysis when using the scale function
env.pca  # pC1 Has most amount of power when compared to all of the variables
summary(env.pca) # Default scaling 2
summary(env.pca, scaling=1)

# Eigenvalues
(ev <- env.pca$CA$eig)
# Apply Kaiser-Guttman criterion to select axes
ev[ev > mean(ev)]
```

Here we plot the PCA analysis

```{r}
# Two PCA biplots: scaling 1 and scaling 2
# ****************************************

# Plots using biplot.rda
dev.new(width=12, height=6, title="PCA biplots - environmental variables - biplot.rda")
par(mfrow=c(1,2))
biplot(env.pca, scaling=1, main="PCA - scaling 1")
biplot(env.pca, main="PCA - scaling 2")  # Default scaling 2
# Smaller the angle between the plot is the closer they are related to eachother

# Plots using cleanplot.pca - NEW VERSION OF THIS FUNCTION wich changed syntax
# A rectangular graphic window is needed for the two plots
dev.new(width=12, height=6, title="PCA biplots - environmental variables - cleanplot.pca")
par(mfrow=c(1,2))
cleanplot.pca(env.pca, scaling=1, mar.percent=0.08)
cleanplot.pca(env.pca, scaling=2, mar.percent=0.04)

```

Here we are using PCA analysis on the species data. But first we need to transform this data

```{r}
# Hellinger pre-transformation of the species data
spe.h <- decostand(spe, "hellinger")
(spe.h.pca <- rda(spe.h))

# Plot eigenvalues and % of variance for each axis
ev <- spe.h.pca$CA$eig
dev.new(title="PCA eigenvalues")
evplot(ev)

# PCA biplots
spe.pca.sc1 <- scores(spe.h.pca, display="species", scaling=1)
spe.pca.sc2 <- scores(spe.h.pca, display="species", scaling=2)

dev.new(title="PCA on fish species", width=12, height=6)
par(mfrow=c(1,2))
cleanplot.pca(spe.h.pca, scaling=1, mar.percent=0.06)
cleanplot.pca(spe.h.pca, scaling=2, mar.percent=0.06)
```

Here is some code to use when doing a quick assumption on the data using PCA

```{r}
# PCA; scaling 1 is the default for biplots
env.PCA.PL <- PCA.newr(env, stand=TRUE)
dev.new(title="PCA on environmental variables - scaling 1")
biplot.PCA.newr(env.PCA.PL)

# PCA; scaling 2 in the biplot
dev.new(title="PCA on environmental variables - scaling 2")
biplot.PCA.newr(env.PCA.PL, scaling=2)
```

#################CORRESPONDANCE ANALYSIS#######################

The code bellow is used in running the analysis and drawing the biplots for the CA including the biplots. Looking at both species and environmental data. If the CA value is greater than 0.6 it indicates a very strong gradient in the data. Scaling affects the eigenvectors but not the eigenvalues.

SOME EXTRA BITS
```{r}
#####################################################USE THIS FOR THE CA analysis
# Chi-square pre-transformation followed by Euclidean distance
spe.t.chi <- decostand(spe.t, "chi.square")
spe.t.D16 <- dist(spe.t.chi)
dev.new(title="D16 on fish species (R-mode)", width=10, height=5)
coldiss(spe.t.D16, diag=TRUE)

```

Chapter 5 CA calculations

```{r}
# CA of the raw species dataset (original species abundances)
# Compute CA
(spe.ca <- cca(spe))
summary(spe.ca)		# default scaling 2
summary(spe.ca, scaling=1)

# Plot eigenvalues and % of variance for each axis
(ev2 <- spe.ca$CA$eig)
dev.new(title="CA eigenvalues")
evplot(ev2)

# CA biplots
dev.new(title="CA biplots", width=14, height=7)
par(mfrow=c(1,2))
# Scaling 1: sites are centroids of species
plot(spe.ca, scaling=1, main="CA fish abundances - biplot scaling 1")
# Scaling 2 (default): species are centroids of sites
plot(spe.ca, main="CA fish abundances - biplot scaling 2")

# A posteriori projection of environmental variables in a CA
# The last plot produced (CA scaling 2) must be active
(spe.ca.env <- envfit(spe.ca, env, scaling=2)) # Scaling 2 is default
plot(spe.ca.env)
# Plot significant variables with a different colour
plot(spe.ca.env, p.max=0.05, col=3)

# Species data table ordered after the CA result
vegemite(spe, spe.ca)
```

Doing the cca AJ way

```{r}
# Compute CA
(spe.ca <- cca(spe))
summary(spe.ca)		# default scaling 2
summary(spe.ca, scaling=1)

# Plot eigenvalues and % of variance for each axis
(ev2 <- spe.ca$CA$eig)
# dev.new(title="CA eigenvalues")
evplot(ev2)

# CA biplots
# dev.new(title="CA biplots", width=14, height=7)
par(mfrow=c(1,2))
# Scaling 1: sites are centroids of species
plot(spe.ca, scaling=1, main="CA fish abundances - biplot scaling 1")
# Scaling 2 (default): species are centroids of sites
plot(spe.ca, main="CA fish abundances - biplot scaling 2")

# A surface plot for the CA
require('viridis')
palette(viridis(8))
par(mar = c(4, 4, 0.9, 0.5) + .1, mfrow = c(2, 2))
with(spe, tmp <- ordisurf(spe.ca ~ Satr, bubble = 3,
                          family = quasipoisson, knots = 2, col = 6,
                          display = "sites", main = "Satr"))
abline(h = 0, v = 0, lty = 3)
with(spe, tmp <- ordisurf(spe.ca ~ Scer, bubble = 3,
                          family = quasipoisson, knots = 2, col = 6,
                          display = "sites", main = "Scer"))
abline(h = 0, v = 0, lty = 3)
with(spe, tmp <- ordisurf(spe.ca ~ Teso, bubble = 3,
                          family = quasipoisson, knots = 2, col = 6,
                          display = "sites", main = "Teso"))
abline(h = 0, v = 0, lty = 3)
with(spe, tmp <- ordisurf(spe.ca ~ Cogo, bubble = 3,
                          family = quasipoisson, knots = 2, col = 6,
                          display = "sites", main = "Cogo"))
abline(h = 0, v = 0, lty = 3)

# A posteriori projection of environmental variables in a CA
# The last plot produced (CA scaling 2) must be active
(spe.ca.env <- envfit(spe.ca, env, scaling = 2)) # Scaling 2 is default
plot(spe.ca.env)
# Plot significant variables with a different colour
plot(spe.ca.env, p.max = 0.05, col = "red")
```





Here we use the CA function similar to the PCA function

```{r}
spe.CA.PL <- CA.newr(spe)
dev.new(title="Species CA with CA() function", width=14, height=8)
biplot.CA(spe.CA.PL, cex=1)

# Ordering of the data table following the first CA axis
# The table is transposed, as in vegemite() output
summary(spe.CA.PL)
t(spe[order(spe.CA.PL$F[,1]), order(spe.CA.PL$V[,1])])
```

########################## PCoA #############################################

 Here we make use of the Bray-curtis dissimiliarity among sites to create a maxtrix into PCoA. the function wascores()- projects weighted averages of species abundance. In this case species are projected as weighted averages of their contributions to the sites, their interpretation with respect to the sites is done in CA. Working with species data.
 
```{r}
spe.bray <- vegdist(spe)
spe.b.pcoa <- cmdscale(spe.bray, k=(nrow(spe)-1), eig=TRUE)
# Plot of the sites
dev.new(title="PCoA on fish species - Percentage difference")
ordiplot(scores(spe.b.pcoa, choices=c(1,2)), type="t", main="PCoA with species weighted averages")
abline(h=0, lty=3)
abline(v=0, lty=3)
# Add weighted average projection of species
spe.wa <- wascores(spe.b.pcoa$points[,1:2], spe)
text(spe.wa, rownames(spe.wa), cex=0.7, col="red")
```

Here we apply the doubs dataset using PCoA. PCoA is run on a euclidean distance matrix compted on Hellinger transformed species abundance matrix. In this case it is usually better to run PCA on the transformed data. Use the species data with the same transformation that was used to compute the dissimilarity matrix.

```{r}
# PCoA and projection of species vectors using function pcoa()
spe.h.pcoa <- pcoa(dist(spe.h))
# Biplots
dev.new(title="PCoA with species vectors", width=14, height=8)
par(mfrow=c(1,2))
# First biplot: Hellinger-transformed species data
biplot.pcoa(spe.h.pcoa, spe.h, dir.axis1=-1) 
abline(h=0, lty=3)
abline(v=0, lty=3)
# Second biplot: standardized Hellinger-transformed species data
spe.std <- scale(spe.h)
biplot.pcoa(spe.h.pcoa, spe.std, dir.axis1=-1) 
abline(h=0, lty=3)
abline(v=0, lty=3)

```

Using the different dissimilarity to show bray-curtis is not euclidean and jaccard is. When working with PCoA one should only use Bray-curtis as this is non euclidean. 

```{r}
# Comparison of PCoA results with Euclidean and non-Euclidean
# dissimilarity matrices
# PCoA on a Hellinger distance matrix
is.euclid(dist(spe.h))
summary(spe.h.pcoa) 
spe.h.pcoa$values

# PCoA on a percentage difference (Bray-Curtis) dissimilarity matrix
is.euclid(spe.bray)
spe.bray.pcoa <- pcoa(spe.bray) 
spe.bray.pcoa$values		# Observe eigenvalues 18 and following

# PCoA on the square root of a percentage difference (Bray-Curtis)
# dissimilarity matrix
is.euclid(sqrt(spe.bray))
spe.braysq.pcoa <- pcoa(sqrt(spe.bray))
spe.braysq.pcoa$values	# Observe the eigenvalues

# PCoA on a percentage difference (Bray-Curtis) dissimilarity matrix with
# Lingoes correction
spe.brayl.pcoa <- pcoa(spe.bray, correction="lingoes")
spe.brayl.pcoa$values		# Observe the eigenvalues, col. 1 and 2

# PCoA on a percentage difference (Bray-Curtis) dissimilarity matrix with
# Cailliez correction
spe.brayc.pcoa <- pcoa(spe.bray, correction="cailliez")
spe.brayc.pcoa$values		# Observe the eigenvalues, col. 1 and 2
```

####################################### Nonmetric Multidimensional Scaling ######################

Here we use the Nonmetric multidimensional scaling

```{r}
spe.nmds <- metaMDS(spe, distance="bray")
spe.nmds
spe.nmds$stress
dev.new(title="NMDS on fish species - Percentage difference")
plot(spe.nmds, type="t", main=paste("NMDS/Percentage difference - Stress =", round(spe.nmds$stress,3)))
```

Creating a shepards diagram: The distance among objects in the ordination plot with original distances. The goodness of fit ordiation is measured as R2 of either linear or non linear regression. looking at species data

```{r}
# Shepard plot and goodness of fit
dev.new(title="NMDS - Shepard plot", width=12, height=6)
par(mfrow=c(1,2))
stressplot(spe.nmds, main="Shepard plot")
gof <- goodness(spe.nmds)
plot(spe.nmds, type="t", main="Goodness of fit")
points(spe.nmds, display="sites", cex=gof*300)
```

#########################################Chapter 6###################################
#####################################RDA############################################

Here i load various packages needed for the RDA or for chapter 6

```{r}
library(ade4)
library(adespatial)
library(vegan)
library(vegan3d)
library(MASS)
library(ellipse)
library(FactoMineR)
```

Next we load the various functions that may be needed in this analysis
Then we once again do the basic analysis on our dataset in order to examine the dataset
Load the data in
In this case we are working with env data

```{r}
# Set aside the variable 'dfs' (distance from the source) for later use
dfs <- env[, 1]

# Remove the 'dfs' variable from the env dataset
env <- env[, -1]
# Recode the slope variable (slo) into a factor (qualitative) 
# variable (to show how these are handled in the ordinations)
slo2 <- rep("very_steep", nrow(env))
slo2[env$slo <= quantile(env$slo)[4]] <- "steep"
slo2[env$slo <= quantile(env$slo)[3]] <- "moderate"
slo2[env$slo <= quantile(env$slo)[2]] <- "low"
slo2 <- factor(slo2, levels=c("low", "moderate", "steep", "very_steep"))
table(slo2)
# Create an env2 data frame with slope as a qualitative variable
env2 <- env
env2$slo <- slo2

# Create two subsets of explanatory variables
# Physiography (upstream-downstream gradient)
envtopo <- env[, c(1:3)]
names(envtopo)
# Water quality
envchem <- env[, c(4:10)]
names(envchem)

# Hellinger-transform the species dataset
spe.hel <- decostand(spe, "hellinger")
```

Now we look at the simples method to work with RDA. y: response matrix, X: matrix of explanitory variables and W: optional matrix of covariables. Working with the species data.

```{r}

# Redundancy analysis (RDA)
# RDA of the Hellinger-transformed fish species data, constrained
# by all the environmental variables contained in env2
(spe.rda <- rda(spe.hel ~ ., env2)) # Observe the shortcut
                                    # formula
summary(spe.rda)	# Scaling 2 (default)
```

Adjusting the R2 values

```{r}
# Canonical coefficients from the rda object
coef(spe.rda)
# Unadjusted R^2 retrieved from the rda object
(R2 <- RsquareAdj(spe.rda)$r.squared)
# Adjusted R^2 retrieved from the rda object
(R2adj <- RsquareAdj(spe.rda)$adj.r.squared)
```

Here we plot the results obtained from the RDA analysis. THis is called the tri entry plot as there are three different enteries in this plot: sites, response variables and the explanitory variables. the arrow heads are added only to the vectors of the quantitative explanitory variables. Workiing with the species data.

```{r}
## Triplots of the rda results (wa scores)
## Site scores as weighted averages (vegan's default)
# Scaling 1: distance triplot
dev.new(title="RDA scaling 1 + wa")
plot(spe.rda, scaling=1, 
	main="Triplot RDA spe.hel ~ env2 - scaling 1 - wa scores")
spe.sc1 <- scores(spe.rda, choices=1:2, scaling=1, display="sp")
arrows(0, 0, spe.sc1[, 1]*0.92, spe.sc1[, 2]*0.92, length=0, lty=1, col="red")

# Scaling 2 (default): correlation triplot
dev.new(title="RDA scaling 2 + wa")
plot(spe.rda, main="Triplot RDA spe.hel ~ env2 - scaling 2 - wa scores")
spe.sc2 <- scores(spe.rda, choices=1:2, display="sp")
arrows(0, 0, spe.sc2[, 1]*0.92, spe.sc2[, 2]*0.92, length=0, lty=1, col="red")

## Triplots of the rda results (lc scores)
## Site scores as linear combinations of the environmental variables
# Scaling 1
dev.new(title="RDA scaling 1 + lc")
plot(spe.rda, scaling=1, display=c("sp", "lc", "cn"), 
	main="Triplot RDA spe.hel ~ env2 - scaling 1 - lc scores")
arrows(0, 0, spe.sc1[, 1]*0.92, spe.sc1[, 2]*0.92, length=0, lty=1, col="red")

# Scaling 2
dev.new(title="RDA scaling 2 + lc")
plot(spe.rda, display=c("sp", "lc", "cn"), 
	main="Triplot RDA spe.hel ~ env2 - scaling 2 - lc scores")
arrows(0, 0, spe.sc2[,1]*0.92, spe.sc2[,2]*0.92, length=0, lty=1, col="red")
```

With permuatations in mind we can now test our RDA results. Frst run the global test and then run the test of canonical axes. The test function is called anova(). It is not useful to apply the kaiser-guttman or broken stick model to these analysis but they are applied to residual, unconstrained axes. Working with the species data.

```{r}
# Global test of the RDA result
anova(spe.rda, permutations=how(nperm=999))
# Tests of all canonical axes
anova(spe.rda, by="axis", permutations=how(nperm=999))
```

How we have the two different analysis and compare there results with eachother.

```{r}
# Partial RDA: effect of water chemistry, holding physiography constant
# Simple interface; X and W may be separate tables of quantitative variables
(spechem.physio <- rda(spe.hel, envchem, envtopo))
summary(spechem.physio)

# Formula interface; X and W variables must be in the same data frame
(spechem.physio2 <- rda(spe.hel ~ pH + har + pho + nit + amm + oxy + bod 
	+ Condition(alt + slo + flo), data=env))
```

Here we test the partial RDA and whether or not it is significant. Draw triplots of the first pair of axes.

```{r}
# Test of the partial RDA (using the results with the formula 
# interface to allow the tests of the axes to be run)
anova(spechem.physio2, permutations=how(nperm=999))
anova(spechem.physio2, permutations=how(nperm=999), by="axis")
# Partial RDA triplots (with fitted site scores) - function plot.cca
# Scaling 1
dev.new(title="Partial RDA scaling 1")
plot(spechem.physio, scaling=1, display=c("sp", "lc", "cn"), 
	main="Triplot RDA spe.hel ~ chem | Topo - scaling 1 - lc scores")
spe3.sc <- scores(spechem.physio, choices=1:2, scaling=1, display="sp")
arrows(0, 0, spe3.sc[, 1]*0.92, spe3.sc[, 2]*0.92, length=0, lty=1, col="red")

# Scaling 2
dev.new(title="Partial RDA scaling 2")
plot(spechem.physio, display=c("sp", "lc", "cn"), 
	main="Triplot RDA spe.hel ~ chem | Topo - scaling 2 - lc scores")
spe4.sc <- scores(spechem.physio, choices=1:2, display="sp")
arrows(0, 0, spe4.sc[,1]*0.88, spe4.sc[,2]*0.88, length=0, lty=1, col="red")
```





















































